---
title: 测试面试常问集合
date: 2023-02-09 11:56:06
permalink: /pages/e27557
categories:
  - 测试
  - testing
tags:
  - 
author: 
  name: kamalyes
  link: https://github.com/kamalyes
---
## TCP和UDP的区别、特点
- TCP的主要特点是：
  1）面向连接。
  2）每一条TCP连接只能是点对点的（一对一）。
  3）提供可靠交付的服务(无差错，不丢失，不重复，且按序到达)(校验和、重传控制、序号标识、滑动窗口、确认应答实现可靠传输。如丢包时的重发控制，还可以对次序乱掉的分包进行顺序控制。)。
  4）提供全双工通信。
  5）面向字节流。
- UDP的主要特点是：
  1）无连接。
  2）尽最大努力交付(不保证可靠交付)。
  3）面向报文。
  4）无拥塞控制。支持一对一、一对多、多对一和多对多的交互通信。
  5）首部开销小（只有四个字段：源端口、目的端口、长度、检验和）。

采用TCP，一旦发生丢包，TCP会将后续的包缓存起来，等前面的包重传并接收到后再继续发送，延时会越来越大。
UDP对实时性要求较为严格的情况下，采用自定义重传机制，能够把丢包产生的延迟降到最低，尽量减少网络问题对游戏性造成影响。

## 关系型数据库与NOSQL
- 关系型数据库  Oracle、DB2、Microsoft SQL Server、Microsoft Access、MySQL
  主要特点：
  1. 关系型数据库支持多个表之间连接查询（join）,非关系型数据库不支持连接查询
  2. 关系型强调数据之间的强关联型，并支持事物来确保数据的增删改查的强一致性，而非关系型数据库对数据的事物则支持的不是很好
  3. 关系型数据库不灵活，是一种二维的数据结构，而且对一行的数据格式类型要求很高，非关系型数据库数据格式则更灵活，数据字段类型也很灵活
- 非关系型数据库 NOSQL(Not Only SQL) Redis、Memchache、MongoDb
  主要特点：
  1. 易扩展，数据之间没有关系的。
  2. 大数据量，高性能。高性能读写非常灵活的。
  3. 灵活的数据模型。不需要事先对存储数据建立字段。
  4. 高可用。
- 总结
  1）非关系型数据库比关系型数据库更容易扩展
  2）非关系型数据库对大量的并发读写支持的更好，性能更高，而关系型由于IO瓶颈，高并发读写速度慢，支持不好
  3）对于数据量很大，而且数据之间无规律，为了能更好的利用这些数据，就可以用非关系数据库
  4）非关系型数据库有Mongdb,Redis,Hbase,关系型数据库有Mysql,Oracle
  5）redis是内存级数据库，所有数据操作都在内存中进行，数据持久化通过RDB和AOF方式
  6）Mysql所有的索引和数据都放在硬盘中，所以对数据的操作会有大量的IO耗时，IO是导致读写慢的主要原因
  7）Mongdb介于二者之间，mongodb的所有数据实际上是存放在硬盘的，所有要操作的数据通过mmap的方式映射到内存某个区域内
  8）传统关系型数据库在数据库高并发读写，对海量的数据存储，对数据库的高可扩展性应用场景性能不好
  9）mongdb更灵活，适用于需求变更，模型无法确定，要进行扩展等场景，mongdb每条数据都可以灵活增加字段

## App测试和Web测试的区别
```
web项目，一般都是b/s架构，基于浏览器的。
App则是C/S的，必须要有客户端。那么在系统测试测试的时候就会产生区别了。
首先从系统架构来看的话，Web测试只要更新了服务器端，客户端就会同步会更新。而且客户端是可以保证每一个用户的客户端完全一致的。但是App端是不能够保证完全一致的，除非用户更新客户端。如果是App下修改了服务端，意味着客户端用户所使用的核心版本都需要进行回归测试一遍。
```

- 性能方面

  1）web页面可能只会关注响应时间。

  2）App则还需要关心流量、电量、CPU、GPU、Memory这些了。

- 兼容方面

  1）Web是基于浏览器的，所以更倾向于浏览器和电脑硬件，电脑系统的方向的兼容，不过一般还是以浏览器的为主。而浏览器的兼容则是一般是选择不同的浏览器内核进行测试（IE、chrome、Firefox）。

  2）App的测试则必须依赖phone或者是pad，不仅要看分辨率，屏幕尺寸，还要看设备系统。系统总的来说也就分为Android和iOS，不过国内的Android的定制系统太多，也是比较容易出现问题的。

  3）相比较web测试，app更是多了一些专项测试；一些异常场景的考虑以及弱网络测试。这里的异常场景就是中断，来电，短信，关机，重启等。而弱网测试是App测试中必须执行的一项测试。包含弱网和网络切换测试。需要测试弱网所造成的用户体验，重点要考虑回退和刷新是否会造成二次提交。需要测试丢包，延时的处理机制。避免用户的流失。

- 安装、卸载、更新：

  1）web测试是基于浏览器的所以不必考虑这些。

  2）app是客户端的，则必须测试安装、更新、卸载。除了常规的安装、更新、卸载还要考虑到异常场景。包括安装时的中断、弱网、安装后删除安装文件，更新的强制更新与非强制更新、增量包更新、断点续传、弱网，卸载后删除App相关的文件等等。
  界面操作
  

现在app产品的用户都是使用的触摸屏手机，所以测试的时候还要注意手势，横竖屏切换，多点触控，事件触发区域等测试。

## Android中造成APP闪退的原因总结
1. 弱网络情况下，服务端响应不及时，可能倒是闪退。（网络异常引起的）
2. 应用版本太低，会导致不兼容，造成闪退。（有些API在老版本中有,在新版本中没有,造成对象为空引起闪退）
3. APP的SDK和手机的系统不兼容。
4. 缓存垃圾过多：由于安卓系统的特性，如果长时间不清理垃圾文件。会导致越来越卡，也会出现闪退情况。
5. 设计不合理，1个接口，拉取的数据量太大，请求结果会很慢，且占用大量内存，APP会闪退（比如，我们现在做的记录仪，进入相册列表时候，要拉取所有图片，拉取太慢了，就闪退了）
6. 不同APP间切换，交互测试，可能会出现闪退。
7. 权限问题。

## 网页很卡的原因
1. 带宽不足、硬件配置低、CPU或者是内存被占满。
2. http请求次数太多。
3. 接收数据时间过长，如下载资源过大。
4. JS脚本过大，阻塞了页面的加载。
5. 网页资源过多、接受数据时间长、加载某个资源慢。
6. DNS解析速度。
详细版
```
带宽不足，首先想到的就是自己网速的问题，但是一般网速在1M以上的，打开网页一般不会是很慢的。网站服务器的带宽不够的话，当大量用户访问的时候，网页的加载也是很慢的，这就是网络的出口端和入口端两个方面

硬件配置低，本机的配置也会是一方面的，但是只要不是老赛扬单核+512M的配置，一般不会是电脑配置的问题。服务器端的配置也是同样的道理。

CPU或者是内存被占满的时候，打开网页很是会很慢的，因为整个电脑都很慢

DNS解析慢，域名的解析是需要专门的域名解析服务器来完成的，DNS解析包括往复解析的次数及每次解析所花费的时间，它们两者的积即是DNS解析所耗费的总时间，在http请求的过程中，域名解析和建立连接占的时间很多。

JS阻塞请求，写的js代码出现问题，解析就会花费很长时间，这两个js请求之间会出现一个很大的空隙，就会导致这段时间的资源加载都被阻塞住，

接受数据时间过长，http请求的大部分时间应该花在后面几个阶段，比如等待响应和接收数据。但是，如果接收数据的时间太长了，长到数百毫秒甚至以秒计算的时候，那也是有问题的。这种情况一般是因为下载的内容太重了，例如大图片、大脚本等。这类问题可以使用GZIP压缩、图片压缩或者JS/CSS的minify等手段来解决。

加载某个资源太慢，如果某个请求比其它的请求多出很多的时间，那么一般情况就是某个资源的加载太慢，导致了整个网页变慢，原因有可能是1)资源在第三方站点上，他们很慢；2)这个资源太大了；3)这个资源使用的域名有问题

后端代码问题，主要有代码冗余、数据库发生锁死、动态请求时间过长等，这就需要RD优化一切可以优化的东西了

前端页面请求的资源过多，onload之前如果有几百行，速度自然会慢的，如果请求的资源不存在，那么速度将会更慢

网页本身中包含了追踪或者是分析用户的工具，从而导致网页的加载时间变的慢，比如之前海盗湾中会给用户的电脑插入挖矿的js脚本
```

## 单元测试、集成测试、系统测试区别
- 粒度不同：单元测试粒度最小，集成测试粒度居中，系统测试粒度最大。
- 测试方式不同：单元测试一般由开发小组采用白盒方式来测试，集成测试一般由开发小组采用白盒加黑盒的方式来测试，系统测试一般由独立测试小组采用黑盒方式来测试。
- 测试内容不同：单元测试主要测试单元是否符合“设计”，集成测试既验证“设计”，又验证“需求”，系统测试主要测试系统是否符合“需求规格说明书”。
- 使用阶段不同：单元测试为开发人员在开发阶段要做的事情，集成测试和系统测试为测试人员在测试周期内级层做的工作。

## APP是用多进程安全还是用多线程安全
多线程程序只要有一个线程死掉，整个进程也死掉了，而一个进程死掉并不会对另外一个进程造成影响，因为进程有自己独立的地址空间。

## GET与POST请求方式的区别
最直观的区别就是GET把参数包含在URL中，POST通过request body传递参数。

- 正常GET和POST的区别的“标准答案”
  1. GET在浏览器回退时是无害的，而POST会再次提交请求。
  2. GET产生的URL地址可以被Bookmark，而POST不可以。
  3. GET请求会被浏览器主动cache，而POST不会，除非手动设置。
  4. GET请求只能进行url编码，而POST支持多种编码方式。
  5. GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。
  6. GET请求在URL中传送的参数是有长度限制的，而POST么有。
  7. 对参数的数据类型，GET只接受ASCII字符，而POST没有限制。
  8. GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息。
  9. GET参数通过URL传递，POST放在Request body中。

- 实际上GET和POST本质上没有区别？
  1）GET和POST它们均是HTTP协议中的发送请求的方法。HTTP的底层是TCP/IP。所以GET和POST的底层也是TCP/IP，也就是说，GET/POST都是TCP链接。GET和POST能做的事情是一样一样的。你要给GET加上request body，给POST带上url参数，技术上是完全行的通的。
  2）GET和POST还有一个重大区别，简单的说：GET产生一个TCP数据包；POST产生两个TCP数据包。
  3）对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）。也就是说，GET只需要汽车跑一趟就把货送到了，而POST得跑两趟，第一趟，先去和服务器打个招呼“嗨，我等下要送一批货来，你们打开门迎接我”，然后再回头把货送过去。因为POST需要两步，时间上消耗的要多一点，看起来GET比POST更有效。因此Yahoo团队有推荐用GET替换POST来优化网站性能。但这是一个坑！跳入需谨慎。为什么？
  1. GET与POST都有自己的语义，不能随便混用。
  2. 据研究，在网络环境好的情况下，发一次包的时间和发两次包的时间差别基本可以无视。而在网络环境差的情况下，两次包的TCP在验证数据包完整性上，有非常大的优点。
  3. 并不是所有浏览器都会在POST中发送两次包，Firefox就只发送一次。

## 请你说一说bug的周期
- Assigned（已指派的）
当一个bug被指认为New之后，将其反馈给开发人员，开发人员将确认这是否是一个bug，如果是，开发组的负责人就将这个bug指定给某位开发人员处理，并将bug的状态设定为“Assigned”
- Open（打开的）或者叫Processing（处理中）
一旦开发人员开始处理bug的时候，他（她）就将这个bug的状态设置为“Open”，这表示开发人员正在处理这个“bug”
- Fixed（已修复的）
当开发人员进行处理（并认为已经解决）之后，他就可以将这个bug的状态设置为“Fixed”并将其提交给开发组的负责人，然后开发组的负责人将这个bug返还给测试组
- Closed（已关闭的）
如果测试人员经过再次测试之后确认bug 已经被解决之后，就将bug的状态设置为“Closed”
- Reopen（再次打开的）
如果经过再次测试发现bug（指bug本身而不是包括因修复而引发的新bug）仍然存在的话，测试人员将bug再次传递给开发组，并将bug的状态设置为“Reopen”
- Rejected（已拒绝）
测试组的负责人接到上述bug的时候，如果他（她）发现这是产品说明书中定义的正常行为或者经过与开发人员的讨论之后认为这并不能算作bug的时候，开发组负责人就将这个bug的状态设置为“Rejected”
- Postponed（延期）
有些时候，对于一些特殊的bug的测试需要搁置一段时间，事实上有很多原因可能导致这种情况的发生，比如无效的测试数据，一些特殊的无效的功能等等，在这种情况下，bug的状态就被设置为“Postponed“

## 请描述一下不同类别的bug
- 代码错误、界面优化、设计缺陷、配置相关、安装部署、安全相关、性能问题、标准规范、测试脚本、其它

## 请问你怎么看待测试，知道哪些测试的类型
- 测试是软件开发中不可或缺的一环，测试通过经济，高效的方法，捕捉软件中的错误，从而达到保重软件内在质量的目的。
- 测试分为功能测试和非功能测试，非功能测试又可以分为性能测试、压力测试、容量测试、健壮性测试、安全性测试、可靠性测试、恢复性测试、备份测试、协议测试、兼容性测试、可用性测试、配置测试、GUI测试。
- 测试的目的是找出软件产品中的错误，是软件尽可能的符合用户的要求。当然软件测试是不可能找出全部错误的
  
## 请你说一下设计测试用例的方法
#### 黑盒测试
  1）`等价类划分`是将系统的输入域划分为若干部分，然后从每个部分选取少量代表性数据进行测试。等价类可以划分为有效等价类和无效等价类，设计测试用例的时候要考虑这两种等价类。
  2）`边界值分析法`是对等价类划分的一种补充，因为大多数错误都在输入输出的边界上。边界值分析就是假定大多数错误出现在输入条件的边界上，如果边界附件取值不会导致程序出错，那么其它取值出错的可能性也就很小。边界值分析法是通过优先选择不同等价类间的边界值覆盖有效等价类和无效等价类来更有效的进行测试，因此该方法要和等价类划分法结合使用。
  3）`正交试验法`是从大量的试验点中挑选出适量的、有代表性的点。正交试验设计是研究多因素多水平的一种设计方法，他是一种基于正交表的高效率、快速、经济的试验设计方法。
  4）`状态迁移法`是对一个状态在给定的条件内能够产生需要的状态变化，有没有出现不可达的状态和非法的状态，状态迁移法是设计足够的用例达到对系统状态的覆盖、状态、条件组合、状态迁移路径的覆盖。
  5）`流程分析法`主要针对测试场景类型属于流程测试场景的测试项下的测试子项进行设计，这是从白盒测试中路径覆盖分析法借鉴过来的一种很重要的方法。
  6）`输入域测试法`是针对输入会有各种各样的输入值的一个测试，他主要考虑 极端测试、中间范围测试，特殊值测试 。
  7）`输出域分析法`是对输出域进行等价类和边界值分析，确定是要覆盖的输出域样点，反推得到应该输入的输入值，从而构造出测试用例，他的目的是为了达到输出域的等价类和边界值覆盖。
  8）`判定表分析法`是分析和表达多种输入条件下系统执行不同动作的工具，他可以把复杂的逻辑关系和多种条件组合的情况表达的即具体又明确；
  9）`因果图法`是用于描述系统输入输出之间的因果关系、约束关系。因果图的绘制过程是对被测系统的外部特征的建模过程，根据输入输出间的因果图可以得到判定表，从而规划出测试用例。
  10）`错误猜测法`主要是针对系统对于错误操作时对于操作的处理法的猜测法，从而设计测试用例
  11）`异常分析法`是针对系统有可能存在的异常操作，软硬件缺陷引起的故障进行分析，分析发生错误时系统对于错误的处理能力和恢复能力依此设计测试用例。

#### 白盒测试
白盒测试也称为结构测试或逻辑驱动测试，是针对被测单元内部是如何进行工作的测试。它根据程序的控制结构设计测试用例，主要用于软件或程序验证。白盒测试法检查程序内部逻辑结构，对所有的逻辑路径进行测试，是一种穷举路径的测试方法，但即使每条路径都测试过了，但仍然有可能存在错误。因为：穷举路径测试无法检查出程序本身是否违反了设计规范，即程序是否是一个错误的程序；穷举路径测试不可能检查出程序因为遗漏路径而出错；穷举路径测试发现不了一些与数据相关的错误。
1）白盒测试需要遵循的原则？
  1. 保证一个模块中的所有独立路径至少被测试一次；
  2. 所有逻辑值均需要测试真（true）和假（false）；两种情况；
  3. 检查程序的内部数据结构，保证其结构的有效性；
  4. 在上下边界及可操作范围内运行所有循环。

2）常用白盒测试方法：
静态测试：不用运行程序的测试，包括代码检查、静态结构分析、代码质量度量、文档测试等等，它可以由人工进行，充分发挥人的逻辑思维优势，也可以借助软件工具（Fxcop）自动进行。
动态测试：需要执行代码，通过运行程序找到问题，包括功能确认与接口测试、覆盖率分析、性能分析、内存分析等。
白盒测试中的逻辑覆盖包括语句覆盖、判定覆盖、条件覆盖、判定/条件覆盖、条件组合覆盖和路径覆盖。
3）六种覆盖标准发现错误的能力呈由弱到强的变化：
1.语句覆盖每条语句至少执行一次。
2.判定覆盖每个判定的每个分支至少执行一次。
3.条件覆盖每个判定的每个条件应取到各种可能的值。
4.判定/条件覆盖同时满足判定覆盖条件覆盖。
5.条件组合覆盖每个判定中各条件的每一种组合至少出现一次。
6.路径覆盖使程序中每一条可能的路径至少执行一次。

## 手功测试和自动化测试的优缺点
手功测试
- 优点：
可以对各种应用程序进行手动测试
更适合生命周期较短的产品
适用于需求频繁变化的项目和GUI不断变化的产品
与自动化测试相比，手工测试的初始投资更便宜
手工测试可以执行临时测试
测试人员无需了解自动化工具
- 缺点；
手工测试在进行回归测试时，非常耗时。
与自动化测试相比，手动测试的可靠性较低，因为它是由人工进行的。所以总会容易出现错误和失误。
从长远来看，相比自动化测试，手工测试代价过于昂贵。

自动化测试
- 优点：
自动化测试执行速度更快
从长远来看，它比手动测试更利于企业长久发展
自动化测试得到结果更可靠
自动化测试更强大、更通用
它主要用于回归测试
可重复使用，可以记录自动化过程
它不需要人工干预。测试脚本可以在无人值守的情况下运行
它有助于增加测试覆盖率
- 缺点：
仅适合长期迭代更新的产品
自动化测试在最初搭建时成本会比较高
大多数收费的自动化工具费用都比较高
它有一些限制，例如处理验证码，获取 UI 的视觉方面，例如字体、颜色、大小等，不适合使用自动化测试

## 如何进行BUG的评测
通常bug管理中，severity分为四个等级blocker、critical、major、minor/trivial。

1、`Blocker（崩溃）`:阻碍开发或测试工作的问题；造成系统崩溃、死机、死循环，导致数据库数据丢失，与数据库连接错误，主要功能丧失，基本模块缺失等问题。如：代码错误、死循环、数据库发生死锁、重要的一级菜单功能不能使用等。（该问题在测试中较少出现，一旦出现应立即中止当前版本测试）`立即处理`

2、`Critical（严重）`:系统主要功能部分丧失、数据库保存调用错误、用户数据丢失，一级功能菜单不能使用但是不影响其它功能的测试。功能设计与需求严重不符，模块无法启动或调用，程序重启、自动退出，关联程序间调用冲突，安全问题、稳定性等。如：软件中数据保存后数据库中显示错误，用户所要求的功能缺失，程序接口错误，数值计算统计错误等。（该等级问题出现在不影响其它功能测试的情况下可以继续该版本测试）`紧急处理`

3、`Major（一般、界面、性能缺陷、兼容性）`:功能没有完全实现但是不影响使用，功能菜单存在缺陷但不会影响系统稳定性。如：操作时间长、查询时间长、格式错误、边界条件错误，删除没有确认框、数据库表中字段过多等。(该问题实际测试中存在最多，合理安排解决Bug，解决率关系版本的优化程度) `正常处理`

4、`Minor/Trivial（次要、易用性及建议性问题）`:界面、性能缺陷，建议类问题，不影响操作功能的执行，可以优化性能的方案等。如：错别字、界面格式不规范，页面显示重叠、不该显示的要隐藏，描述不清楚，提示语丢失，文字排列不整齐，光标位置不正确，用户体验感受不好，可以优化性能的方案等。（此类问题在测试初期较多，优先程度较低；在测试后期出现较少，应及时处理）`有时间再处理`

## 软件质量的6个特征
- 功能性：软件所实现的功能满足用户需求的程度．功能性反映了所开发的软件满足用户称述的或蕴涵的需求的程度，即用户要求的功能是否全部实现了。
- 可靠性：在规定的时间和条件下，软件所能维持其性能水平的程度。可靠性对某些软件是重要的质量要求，它除了反映软件满足用户需求正常运行的程度，且反映了在故障发生时能继续运行的程度。
- 易使用性：对于一个软件，用户学习、操作、准备输入和理解输出时，所做努力的程度。易使用性反映了与用户的友善性，即用户在使用本软件时是否方便。
- 效率：在指定的条件下，用软件实现某种功能所需的计算机资源（包括时间）的有效程度。效率反映了在完成功能要求时，有没有浪费资源，此外"资源";这个术语有比较广泛的含义，它包括了内存、外存的使用，通道能力及处理时间。
- 可维修性：在一个可运行软件中，为了满足用户需求、环境改变或软件错误发生时，进行相应修改所做的努力程度。可维修性反映了在用户需求改变或软件环境发生变更时，对软件系统进行相应修改的容易程度。一个易于维护的软件系统也是一个易理解、易测试和易修改的软件，以便纠正或增加新的功能，或允许在不同软件环境上进行操作。
- 可移植性：从一个计算机系统或环境转移到另一个计算机系统或环境的容易程度。

## 接口几大要素
- 接口访问地址：协议://IP地址或域名（端口号）/应用名/功能名
- 请求方法：get、post、delate、put 等
- 参数：用户使用接口时，需要向接口提供的数据
- 返回值：接口给用户的反馈结果

## Http协议特点
- 简单快速——客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。
- 灵活——允许传输任意类型的数据对象。正在传输的类型由Content-Type（Content-Type是HTTP包中用来表示内容类型的标识）加以标记。
- 无连接——每次只处理一个请求：限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。Keep-Alive 功能使客户端到服务器端的连接持续有效，当出现对服务器的后继请求时，Keep-Alive 功能避免了建立或者重新建立连接。
- 无状态——不记录任何信息：是指协议对于事务处理没有记忆能力，服务器不知道客户端是什么状态。即我们给服务器发送 HTTP 请求之后，服务器根据请求，会给我们发送数据过来，但是，发送完，不会记录任何信息。两种用于保持 HTTP 连接状态的技术，一个是 Cookie，而另一个则是 Session。

## 软件测试的流程是什么

- 需求调研：全面了解系统概况、应用领域、软件开发周期、软件开发环境、开发组织、时间安排、功能需求、性能需求、质量需求及测试要求等。
- 根据系统概况进行项目所需的人员、时间和工作量估计以及项目报价；制定初步的项目计划。
- 测试准备：组织测试团队、培训、建立测试和管理环境等。
- 测试设计：按照测试要求进行每个测试项的测试设计，包括测试用例的设计和测试脚本的开发等。
- 测试实施：按照测试计划实施测试。
- 测试评估：根据测试的结果，出具测试评估报告。

## 当开发人员说不是BUG时，你如何应付

开发人员说不是bug，有2种情况
- 需求没有确定：可以找来产品经理进行确认，需不需要改动，3方商量确定好后再看要不要改。
- 非正常操作且外网用户不可能触发：这个时候，先尽可能的说出是BUG的依据是什么？如果还是不行，那我可以给这个问题提出来,跟开发经理和测试经理进行确认,如果要修改就改,如果不要修改就不改。
- 其实有些真的不是bug，我也只是建议的方式写进TD中，如果开发人员不修改也没有大问题。如果确定是bug的话，一定要坚持自己的立场，让问题得到最后的确认。

## 常见的性能测试方法有哪些，以及每类测试方法的目的是什么

- 基准测试：确保测试环境无问题，初步评估每次只是单独运行一个交易时，当前系统的响应时间是否够快，各服务器的CPU、内存耗用是否合理;
- 单一交易并发测试：确保数据库不存在线程死锁等问题，评估在只是单独运行一个交易时，其系统的响应时间是否够快，各服务器的CPU、内存耗用是否合理。
- 混合场景测试：模拟真实生产场景，评估其系统各交易的响应时间是否够快，各服务器的CPU、内存是否合理。
- 浪涌测试场景：模拟高峰与低峰业务处理量，评估系统各服务器的CPU、内存耗用是否合理。
- 稳定性测试场景：模拟不间断运行系统，评估系统是否可高效不间断稳定运行。
- 容量测试场景：通过不间断逐步加大用户数或业务处理量，确定在特定环境下，预测其系统所能承载的最大用户并发数或最大的业务处理量，从而为项目组提供扩容依据。

## 解释几个常用的性能指标的名称与具体含义。

1）事务：（全称：transaction），单位：个，即用户在准备进行一个操作到完成操作的过程
2）思考时间：（全称：thinktime），单位：秒，一般与事务组合使用，例如在A事务后或者在A事务前增加一个2秒的思考时间，即指每2秒钟运行一次A事务
3）集合点：（全称：rendezous），一般与事务组合使用，例如在A事务前增加一个集合点，且用户并发数为10用户并发，即指10用户每次均需完全到达这个集合点后，在一次性进行并发发起请求，在性能测试中，通常将未设置集合点的并发叫做广义并发（因系统处理能力有限，存在排队概念，因此会导致用户发起的请求顺序有先有后），将设置集合点的并发叫做狭义并发（即客户端一次性想服务器发起请求），一般，性能测试所采用的模式为广义并发模式。
4）事务响应时间：（全称:transaction response time），单位：秒。其主要作用为评估当前系统的响应时间的快慢。
5）事务TPS：(全称transaction per second),事务处理能力，单位：笔/秒，其主要作用为评估当前服务器的处理能力。
6）并发用户数：（全称:Running vusers），单位：个，其主要作用为用来评估当前服务器的负载压力。并发用户数的计算公式：事务响应时间*事务TPS≈并发用户数
7）吞吐量：（全称：throughput），单位：字节，即指客户端在向服务器端发起请求后，其服务器的返回信息。吞吐量的计算公式为：总事务TPS*总返回字节数*运行时间≈吞吐量。
8）点击数：（全称hits per second），单位；次/秒，即每秒客户端向服务器端发起的总请求数，其主要作用为用来评估当前服务器的负载压力。
9）通过事务数：单位：个，即系统在运行一段时间内其事务的总计完成事务数
10）失败事务数：单位：个，即系统在运行一段时间内其事务的总计完成失败事务数
11）事务通过率：即指系统在运行一段时间内其事务完成的成功率。其主要作为是用来评估当前系统的稳定运行处理能力。事务通过率的计算公式：成功事务数/成功事务数+失败事务数*100%
12）CPU资源利用率：即系统在运行一段时间内，其各相关服务器CPU的资源耗用情况

## 请问您是如何得到性能测试需求？怎样针对需求设计、分析是否达到需求？
- 查看需求文档，从中提取性能测试需求，与用户交流，了解实际使用情况。
- 结合业务信息设计操作场景总结出需测试的性能关键指标。
- 执行用例后根据提取关键性能指标来分析是否满足性能需求。

## 客户交付一个性能测试项目，请阐述你的实施流程
- 测试设计阶段
  1） 了解被测系统的性能需求，定义测试目标与范围；
  2） 了解系统的技术信息，如系统架构
  3） 确定测试方案，进度安排，并制定测试计划，场景设置方案及需收集的测试数据
  4） 同相关人员协商讨论测试方案
  5） 准备测试收集模板，不同项目的性能测试，需收集的数据不同，针对性的制定一个模板更符合需要

- 测试环境准备

1） 技术准备：选择性能测试工具，测试方案中涉及到的技术问题;测试数据的收集方案实现；如：如何监控系统资源等；
2） 搭建测试环境
3） 创建初始数据：如虚拟用户使用的账号等；

- 测试执行阶段
1） 录制脚本
2） 调试脚本
3） 执行场景；
4） 收集测试数据，并简单整理

- 测试分析阶段
1） 分析测试数据
2） 提交测试报告

## 一般什么时候开始进行性能测试
被测系统的正常业务流程通过，即集成测试通过后。

## 响应时间和吞吐量之间的关系是什么?
- 响应时间的定义：响应时间是提交请求和返回该请求的响应之间使用的时间。
- 吞吐量的定义：吞吐量是对单位时间内完成的工作量的量度。
结论：响应时间越短，单位时间内的吞吐量越大；响应时间越长，单位时间内的吞吐量越小。
